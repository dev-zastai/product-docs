Today we’re going to show you an interesting example of zast deal with fake fixes. 
## 1. Vulnerability Assessed by zast.ai - Command Injection
Let's see the 1st vulnerability report as below:

![]({{'/assets/img/FakeFixes/1.png' | relative_url }})

Zast.ai located the taint source and taint sink, providing detailed information in its report. And, it included a POC that shows a malicious payload executing a shell command. This clearly reveals a significant security risk, as the application handles the input without proper checks, allowing the threat actors to run arbitrary commands.
When this report was shown to the team, a discussion unfolded.
"A critical vulnerability was reported by zast.ai, we need to address it immediately."
"What if we add Base64 encoding to the input? That might help obscure it and prevent exploitation."
"Hmm, it might be worth trying. Let’s implement that and submit it back to zast.ai for further testing."
After implementing the first patch, the team resubmitted the application to zast.ai for reassessment. Now, let's see what happens next.

## 2. 1st Patch - Base64 Encoding
After zast.ai finished the second round assessment and provided the report below:

![]({{'/assets/img/FakeFixes/2.png' | relative_url }})

We can see that the taint source remained the same in both reports, indicating that the underlying vulnerability was unchanged. In the taint sink, zast.ai accurately pinpointed the Base64 encoding applied to obscure the input.
To validate that the vulnerability still existed, zast.ai provided a POC. It shows how a request with an encoded shell command was sent, attempting to bypass superficial checks. Despite the encoding, the application processed the input without adequate validation, allowing the command to execute successfully.
Zast.ai successfully revealed the use of Base64 encoding as an attempt to obscure the input, demonstrating its exceptional analytical capabilities in identifying persistent vulnerabilities.
When this report was presented to the team, the security team leader expressed his thoughts to the consultant from us: "I'm impressed that zast.ai cracked the Base64 encoding so easily. But, I’m confident I can write code that zast won't be able to exploit. Let me try something different." The following day, he resubmitted the application to zast.ai for a third assessment, without revealing any details about the second patch.

## 3. 2nd Patch - Prefix Matching
Let's see how zast.ai works this time:

![]({{'/assets/img/FakeFixes/3.png' | relative_url }})

The taint source stays the same, so the vulnerability wasn't fixed. Then, let's look into the taint sink, the code implemented a prefix validation for the Base64-decoded command, allowing execution only if the command starts with "secret." This input validation mechanism mitigates potential command injection risks while using the substring(6) method to remove the prefix, ensuring that only specific commands are executed.
Again, the POC validate the command injection vulnerability by sending a Base64-encoded shell command with a prefix match to a specified URL. By combining the prefix "secret" with the command, it tests whether the server is susceptible to remote code execution. Additionally, it uses HTTP headers to mimic legitimate requests, revealing potential security weaknesses in the application's input handling.

We sent the report to the security team, and they came by to share their feedback.
"I’m genuinely impressed by zast.ai’s analytical capabilities. It uncovered vulnerability with such precision!"
"Absolutely! Even with our attempts to obscure the flaw through base64 encoding and prefix matching, it saw right through it."
"What stands out about zast.ai is how it operates differently from traditional black-box and white-box testing tools."
"That’s the game changer! This approach enables it to identify vulnerabilities in ways traditional methods simply can’t match."
"It really sets a new standard for vulnerability detection. I can’t help but wonder how we ever managed without it!"
We're pleased to receive this feedback from our client, but this is exactly how zast.ai works, just as we expected. Afterwards, we also provided some suggestions for fixing the vulnerability.

## 4. Zast.ai's Edge in Vulnerability Detection
From this case, we can see that after two patches, the vulnerability has become much harder to spot. Yet, zast.ai was able to uncover and confirm it using its advanced large language model. As our client highlighted, zast.ai truly stands out from traditional methods like black-box and white-box testing. 
While black-box testing examines the system from an external perspective and relies on input/output, it often suffers from limited coverage, as it only tests predefined scenarios based on expected inputs. This approach can overlook vulnerabilities that occur under unexpected conditions or rare input combinations, making it less effective in identifying complex security flaws. In contrast, white-box testing inspects the internal workings of the code, providing a more thorough analysis but requiring extensive knowledge of the system architecture.
Zast.ai, on the other hand, employs smart analysis of taint sinks to accurately locate taint sources, it then leverages its LLM to generate POC exploits and verify their correctness.

Visit zasta.ai now to try it and keep your systems secure! We also expect to hear your examples of vulnerability cases and remediation strategies. Join us in the conversation and let's collaborate on advancing vulnerability research and exploitation techniques together!